{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# An Experimental Journey With Data to Inspire Your Work\n\n## Introduction \n\nThe Experiential Journey with Data to Inspire Your Work session will make you think differently about data and how it can solve problems! You will hear surprising use case that will make you think, sometimes laugh and hopefully inspire your own work. The use case and introductory material includes a hands-on experiential journey described below. The most valuable part of this session is that it is designed to help you gain experience and relate it to your work \u2013 so that when you leave you have a plan of action on how you can make data more useful in your organization to solve a key challenge.\n\nA real-business application of analytics in \u201cImproving Customer Experiences with Real-Time Insights\u201d will be used as an example during the workshop. This experiential session will include a step by step journey on \u201cHow data science is helping companies to predict the customer experience journey and proactively address the issues, leading to the improvement of Net Promoter Score\u201d. The session will also highlight the importance of using AI, Canvas, CRISP-DM (Cross Industry Standard Process for Data Mining) and Agile in Data Science projects.\n\nThe methodology involves consuming historical Net Promoter Score (NPS) data; using machine learning and artificial intelligence to identify the most important features and created an algorithm to predict the customer experience.\n\n## Background\n\nNPS has become the industry standard customer loyalty measurement. Businesses see customer experience as an imperative and would like to run analytics on and predict customer experience. Since competition is rife, keeping customers happy so they do not move their investments elsewhere is key to maintaining profitability.\n\nImproving the customer experience is valuable because of its effect on our bottom line. Creating an ultimate experience that appeals to both the heart and the head is our goal. Customers give their money, fans give their hearts. 44% of consumers say that majority of customer experiences are bland and 69% of consumers say that emotions count for half their experiences.\n\n\n## Approach\n\nIn this notebook, we'll use scikit-learn to predict the customer experience. scikit-learn, which is a machine learning library for the Python programming language, provides implementations of many classification algorithms. \nHere, we will apply multiple classification algorithms, evaluate the performance, and select the best peroforming algorithm based on performance metrics.\n\nTo help visualize what we are doing, we'll use 2D and 3D charts to show how the classes look with matplotlib and scikitplot python libraries.\n\n<a id=\"top\"></a>\n## Table of Contents\n\n1. [Introduction to Notebook](#getting_started)\n\n\n2. [Install packages and verify the version](#load_libraries)\n\n\n3. [Data Exploration](#explore_data)\n\n\n4. [Feature Extraction](#prepare_data)\n\n\n5. [Feature Scaling](#feature_extraction)\n\n\n6. [Feature Selection](#feature_scaling)\n\n\n7. [Split data into train and test sets](#split_data)\n\n\n8. [Measure Model Performance](#model_selection)\n\n\n9. [Evaluate and Select Model](#performance_metric)\n\n\n10. [Save Model](#evaluate_model)\n\n\n11. [Deployment](#deployment)\n\n\n12. [Make Predictions](#interpretation)"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"getting_started\"></a>\n## 1. Introduction to Notebook\n[Top](#top)\n\nQuick set of instructions to work through the notebook (If you are new to Notebooks, here's a quick overview of how to work in this environment).\n\n**a.** Notebook is a document representing all input and output of operations. This includes code, text input and numerical, text and rich media output. These files have ipynb extensions.\n\n**b.** The notebook has 3 types of cells [**code cells, markdown cells**, and raw cells - markdown (text)]. \n\n   - Code cell allows you to edit and write new code, with full syntax highlighting and tab completion.\n\n   - Markdown cell allows to  document the computational process in a literate way, alternating descriptive text with code, using rich text.\n\n   - Raw cells provide a place in which you can write output directly.\n\n**c.** Each cell with code can be executed independently or together (see options under the Cell menu). When working in this notebook, we will be running one cell to provide a hands-on experiential journey.\n\n\n**d.** To run the cell, position cursor in the code cell and click the Run (arrow) icon. The cell is running when you see the * next to it. Some cells have printable output.\n\n\n**e.** Work through this notebook by reading the instructions and executing code cell by cell. Some cells will require modifications before you run them. "}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"load_libraries\"></a>\n## 2. Load packages and verify the version\n[Top](#top)\n\nLibrary/ Package is collection of various packages. There is no difference between package and python library conceptually.\n\nModule is a set of functions, globals and classes that you can import. Package or library is a set of modules."}, {"metadata": {}, "cell_type": "code", "source": "%%capture\n%matplotlib inline\n#Built-in magic commands https://ipython.readthedocs.io/en/stable/interactive/magics.html\n\n#Load packages and libraries\n\n#Provides information about constants, functions and methods of the Python interpreter \n#(https://docs.python.org/3/library/sys.html)\nimport sys \n\n#Scientific Computing (https://numpy.org/)\nimport numpy as np \n\n#Data manipulation and Analysis (https://pandas.pydata.org/pandas-docs/stable/)\n!pip install --user --upgrade pandas\nimport pandas as pd\n\n#Import and export spreadsheets and databases (https://docs.python.org/3/library/csv.html)\nimport csv \n\n#Manipulate dates and times (https://docs.python.org/3/library/datetime.html#module-datetime)\nfrom datetime import datetime\nimport time\n\n#Exploratory data analysis reports helps with quick data analysis (https://github.com/sfu-db/dataprep#dataprep)\n!pip install dataprep\nfrom dataprep.eda import plot, plot_missing, plot_correlation\n\n#Bokeh is an interactive visualization library for modern web browsers (https://docs.bokeh.org/en/latest/index.html#)\n!pip install bokeh \nfrom bokeh.resources import INLINE\nimport bokeh.io\nbokeh.io.output_notebook(INLINE)\n\n#Profile reports helps with quick data analysis(https://github.com/pandas-profiling/pandas-profiling)\n!pip install pandas-profiling[notebook]\nfrom pandas_profiling import ProfileReport\n\n#Prerequisite for pandas-profiling (https://ipywidgets.readthedocs.io/en/latest/)\n!pip install ipywidgets==7.5.1 \nfrom ipywidgets import widgets\n\n#Plotting library https://matplotlib.org/\n!pip install matplotlib\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n#Python client library to quickly get started with the various Watson Developer Cloud services\n!pip install ibm_watson \n\n#Token-based Identity and Access Management (IAM) authentication https://github.com/watson-developer-cloud/python-sdk\n#allows error handling in more complex programs #https://ibm-watson-iot.github.io/iot-python/exceptions/\nfrom ibm_watson import ApiException \nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator  \n\n#Analyzes concepts, entities, keywords, categories, sentiment, emotion, relations, and semantic roles \n#github https://ibm.biz/Bdqf2U demo https://ibm.biz/Bdqf25\nfrom ibm_watson import NaturalLanguageUnderstandingV1 \nfrom ibm_watson.natural_language_understanding_v1 import Features, SentimentOptions, EmotionOptions\n\n#Provides complete access to the IBM Cloud Object Storage API\n!pip install boto3 \nimport ibm_boto3\nfrom ibm_botocore.client import Config, ClientError\n\n#Classification, Regression, Clustering, Dimensionality Reduction,Model Selection and Preprocesing (https://scikit-learn.org/)\n!pip install sklearn  \nimport sklearn \n#Preprocessing data #https://scikit-learn.org/stable/modules/preprocessing.html\nfrom sklearn import preprocessing \n#Perform a train-test split\nfrom sklearn.model_selection import train_test_split\n#Transforms between zero and one\nfrom sklearn.preprocessing import MinMaxScaler \n#Model evaluation metrics\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\n#Statistical graphics https://seaborn.pydata.org/introduction.html\nimport seaborn as sns", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Check version\nprint(\"Python %d.%d.%d%s%s\"%sys.version_info)\nprint(\"Pandas %s\"%pd.__version__)\nprint(\"Numpy %s\"%np.__version__)\nprint(\"Scikit-learn %s\"%sklearn.__version__)\nprint(\"CSV %s\"%csv.__version__)\nprint(\"IBM boto3 %s\"%ibm_boto3.__version__)\nprint(\"Matplotlib %s\"%matplotlib.__version__)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"explore_data\"></a>\n## 3. Data exploration\n[Top](#top)"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"load_libraries\"></a>\n### 3.1. Load and read the files from GitHub\n\n[Top](#top)"}, {"metadata": {}, "cell_type": "code", "source": "#assign the urls of the files\nnps = \"https://raw.githubusercontent.com/neemadan/An-Experiential-Journey-With-Data-to-Inspire-Your-Work/master/nps_dataset.csv\"\n\n#read the files from the links and store in a dataframe\nnps = pd.read_csv(nps)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"load_libraries\"></a>\n### 3.2. Explore the data and perform quality audit [DataPrep.eda and Pandas Profiling](https://towardsdatascience.com/exploratory-data-analysis-dataprep-eda-vs-pandas-profiling-7137683fe47f)\n\n[Top](#top)"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Option 1: DataPrep.eda (2020) is a Python library for doing EDA produced by SFU\u2019s Data Science Research Group."}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "#Generate Data Summary\nbokeh.io.output_notebook(INLINE)\nplot(nps)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Analyze select column for correlation\nplot_correlation(nps, 'sentiment_overall')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Option 2: Pandas Profiling is an open source Python module with which we can quickly do an exploratory data analysis with just a few lines of code."}, {"metadata": {}, "cell_type": "markdown", "source": "#This package takes time (approx 20-30 mins), so please feel free to change this Markdown to Code cell and run this post the workshop.\nprofile = ProfileReport(nps, title=\"Pandas Profiling Report\")\nprofile"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"feature_extraction\"></a>\n## 4. Feature Extraction\n[Top](#top)"}, {"metadata": {}, "cell_type": "code", "source": "#This step assigns the columns by type for transformation to be applied (numerical, categorical, and categorical with high cardinality)\nnumcols = ['likelihood_to_recommend','assignment_count','meaningful_comm_count', 'first_meaningful_comm_duration_mins', 'all_avg_meaningful_comm_duration_mins',\n           'age_of_account_days', 'life_time_spend_usd', 'monthly_recurring_revenue_usd', 'ticket_duration_days', 'sentiment_overall', 'anger_overall', 'disgust_overall', \n           'fear_overall', 'joy_overall', 'sadness_overall', 'sentiment_last3_conversation', 'anger_sentiment_last3', 'disgust_sentiment_last3', \n           'fear_sentiment_last3', 'joy_sentiment_last3', 'sadness_sentiment_last3', 'sentiment_last_conversation', 'anger_last_conversation', 'disgust_last_conversation', \n           'fear_last_conversation', 'joy_last_conversation', 'sadness_last_conversation', 'sentiment_short_description', 'anger_short_description',\n           'disgust_short_description', 'fear_short_description', 'joy_short_description', 'sadness_short_description', 'sentiment_description', 'anger_description', \n           'disgust_description', 'fear_description', 'joy_description', 'sadness_description']\n           \ncatcols_dummy = ['support_plan','account_type', 'sr_severity','technology_level_2', 'technology_level_3','case_origination_source', 'case_origination_user_type', \n                 'dayofweek', 'timewindow', 'severity_change','tribe_level_1', 'tribe_level_2']\n\ncatcols_hash = ['technology_level_1','catalog_name', 'country', 'geography', 'region']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#This step performs one hot encoding on categorical variables and hashing on categorical variables with high cardinality\nnps_select = pd.concat([nps[numcols], pd.get_dummies(nps[catcols_dummy]),nps[catcols_hash]],axis=1)\n\nfor cat in catcols_hash:\n    nps_select[cat] = nps_select[cat].apply(hash)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"feature_scaling\"></a>\n## 5. Feature Scaling\n[Top](#top)"}, {"metadata": {}, "cell_type": "code", "source": "#This step assigns the target variable to y and other features to X\ny = nps_select['likelihood_to_recommend']\nX = nps_select.copy()\ndel X['likelihood_to_recommend']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#This steps converts all the values in the dataframe to numeric\nX = X.apply(pd.to_numeric, errors='coerce')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#This step assigns mean value to blank cells and thereafter uses MinMax to scale the data\n\nX = X.fillna(X.mean())\n\nscaler = MinMaxScaler()\nscaler = MinMaxScaler(feature_range=(0, 1), copy=True)\nscaler.fit(X)\n\nX = pd.DataFrame(scaler.transform(X), index=X.index, columns=X.columns)\ndisplay(X.head())", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"feature_scaling\"></a>\n## 6. Feature Selection\n[Top](#top)\n\nThis is a filter-based method.  We check the absolute value of the Pearson's correlation between the target and numerical features in our dataset. We keep the top n features based on this criterion."}, {"metadata": {}, "cell_type": "code", "source": "feature_name = list(X.columns)\n# no of maximum features we need to select\nnum_feats=30", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Pearson's Correlation\ndef cor_selector(X, y,num_feats):\n    cor_list = []\n    feature_name = X.columns.tolist()\n    # calculate the correlation with y for each feature\n    for i in X.columns.tolist():\n        cor = np.corrcoef(X[i], y)[0, 1]\n        cor_list.append(cor)\n    # replace NaN with 0\n    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n    # feature name\n    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n    # feature selection? 0 for not select, 1 for select\n    cor_support = [True if i in cor_feature else False for i in feature_name]\n    return cor_support, cor_feature\ncor_support, cor_feature = cor_selector(X, y,num_feats)\nprint(str(len(cor_feature)), 'selected features:')\nprint(cor_feature)", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "#Select the top feature to use as in input to train the model\ntop_30_select = X[cor_feature[:30]]\ntop_30_select", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"feature_scaling\"></a>\n## 7. Split data into train and test sets\n\n[Top](#top)"}, {"metadata": {}, "cell_type": "code", "source": "#This step perform a train-test split\n\nX_train, X_test, y_train, y_test = train_test_split(top_30_select, y, test_size=0.30, random_state=123)\nprint(\"train and test data shape=\")\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\nprint(\"testing data likelihood=\")\nprint(\"1_Promoter=\",np.sum(y_test))\nprint(\"0_Non Promoter=\",len(y_test)-np.sum(y_test))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"feature_scaling\"></a>\n## 8. Measure Model Performance\n\n[Top](#top)"}, {"metadata": {}, "cell_type": "code", "source": "def calculate_metrics(y_true,y_pred):\n    print(\"precision, recall, and f1 score:\", precision_recall_fscore_support(y_true, y_pred,average='macro'))\n    print(\"accuracy score:\", accuracy_score(y_true, y_pred))\n    print(confusion_matrix(y_true, y_pred,labels=[0,1]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.linear_model import LogisticRegression\nclf1 = LogisticRegression(random_state=0, solver='lbfgs',class_weight=\"auto\").fit(X_train, y_train)\ny_pred= clf1.predict(X_test)\ncalculate_metrics(y_test,y_pred);", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.linear_model import SGDClassifier\nclf2 = SGDClassifier(max_iter=1000, tol=1e-3,class_weight=\"balanced\").fit(X_train, y_train)\ny_pred= clf2.predict(X_test)\ncalculate_metrics(y_test,y_pred);", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn import svm\nclf3 = svm.SVC(gamma='scale',class_weight=\"balanced\").fit(X_train, y_train)\ny_pred= clf3.predict(X_test)\ncalculate_metrics(y_test,y_pred)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.neighbors import KNeighborsClassifier\nclf4 = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\ny_pred= clf4.predict(X_test)\ncalculate_metrics(y_test,y_pred)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.gaussian_process import GaussianProcessClassifier\nclf5 = GaussianProcessClassifier(max_iter_predict = 300, random_state=0).fit(X_train, y_train)\ny_pred= clf5.predict(X_test)\ncalculate_metrics(y_test,y_pred)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.naive_bayes import MultinomialNB \nclf7 = MultinomialNB().fit(X_train, y_train) \ny_pred= clf7.predict(X_test) \ncalculate_metrics(y_test,y_pred)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn import tree \nclf8 = tree.DecisionTreeClassifier(class_weight=\"balanced\").fit(X_train, y_train) \ny_pred= clf8.predict(X_test) \ncalculate_metrics(y_test,y_pred)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.ensemble import RandomForestClassifier \nclf9 = RandomForestClassifier(n_estimators=10, max_depth=None,min_samples_split=2, random_state=0,class_weight=\"balanced\").fit(X_train, y_train) \ny_pred= clf9.predict(X_test) \ncalculate_metrics(y_test,y_pred)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.ensemble import GradientBoostingClassifier\nclf10 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train, y_train)\ny_pred= clf10.predict(X_test) \ncalculate_metrics(y_test,y_pred)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.ensemble import VotingClassifier\nclf11 = VotingClassifier(estimators=[('svm', clf9), ('rf', clf10)], voting='hard').fit(X_train, y_train)\ny_pred= clf11.predict(X_test)\ncalculate_metrics(y_test,y_pred)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"feature_scaling\"></a>\n## 9. Evaluate and Select Model\n\n[Top](#top)"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "from sklearn.metrics import confusion_matrix #, plot_confusion_matrix\n\nacc_log = pd.DataFrame(columns=[\"Classifier\", \"Accuracy\"]) #create accuracy log dataframe\nclassifiers = [clf1, clf2, clf3, clf4, clf5, clf8, clf9, clf10, clf11] #list classifiers\n\nfor clf in classifiers:\n    name = clf.__class__.__name__ #Get and print classifier name\n    print(name)\n    y_pred= clf.predict(X_test)\n    \n    print(precision_recall_fscore_support(y_test, y_pred,average='macro'))\n    acc = accuracy_score(y_test, y_pred) #Get and print accuracy\n    print(\"Accuracy: {:.2%}\".format(acc)) \n    print(confusion_matrix(y_test, y_pred,labels=[0,1])) \n    #plot_confusion_matrix(clf, x_train, y_train, cmap=plt.cm.Blues)\n\n    log_entry = pd.DataFrame([[name, acc*100]], columns=[\"Classifier\", \"Accuracy\"])\n    acc_log = acc_log.append(log_entry)\n    print(\"\")\n\n#Format and print comparison of accuracy\nacc_log = acc_log.sort_values(['Accuracy'], ascending = False)\ndisplay(acc_log)\nsns.set_color_codes(\"muted\")\nsns.barplot(x='Accuracy', y='Classifier', data=acc_log, color=\"b\")\n\nplt.xlabel('Accuracy %')\nplt.title('Classifier Accuracy')\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"feature_scaling\"></a>\n## 10. Save the Model\n\n[Top](#top)"}, {"metadata": {}, "cell_type": "markdown", "source": "### Connection to WML\n\nAuthenticate the Watson Machine Learning service on IBM Cloud. You need to provide platform api_key and instance location.\n\n1. Your Cloud API key can be generated by going to the [Users section](https://cloud.ibm.com/iam#/users) of the Cloud console. From that page, click your name, scroll down to the API Keys section, and click Create an IBM Cloud API key. Give your key a name and click Create, then copy the created key and paste it below. \n2. You can check your instance location in your Watson Machine Learning (WML) Service instance details. Pick the name corresponding to the region listed on the service details page:\n\n```\nName            Display name\nau-syd          Sydney\nin-che          Chennai\njp-osa          Osaka\njp-tok          Tokyo\nkr-seo          Seoul\neu-de           Frankfurt\neu-gb           London\nca-tor          Toronto\nus-south        Dallas\nus-south-test   Dallas Test\nus-east         Washington DC\nbr-sao          Sao Paolo\n\n```\n\n"}, {"metadata": {}, "cell_type": "code", "source": "api_key = \"INSERT API HERE\"\nlocation = \"INSERT LOCATION NAME HERE\"\nwml_credentials = {\n    \"apikey\": api_key,\n    \"url\": 'https://' + location + '.ml.cloud.ibm.com'\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%%capture\n\n!pip install -U ibm-watson-machine-learning", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\nclient = APIClient(wml_credentials)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Working with spaces\n\nFirst, you need to create a space that will be used for your work. If you do not have space already created, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=cpdaas) to create one.\n\n    1. Click New Deployment Space\n    2. Create an empty space\n    3. Select Cloud Object Storage\n    4. Select Watson Machine Learning instance and press Create\n    5. Copy space_id and paste it below\n"}, {"metadata": {}, "cell_type": "code", "source": "space_id = 'INSERT SPACE ID HERE'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# you should see your space listed below\nclient.spaces.list(limit=10)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# To be able to interact with all resources available in Watson Machine Learning, you need to set space which you will be using.\nclient.set.default_space(space_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#This steps is one time to save the model and needs to be rerun for re-traiing purpose only.\nsofware_spec_uid = client.software_specifications.get_id_by_name(\"default_py3.7\")\nmetadata = {\n            client.repository.ModelMetaNames.NAME: 'Scikit model',\n            client.repository.ModelMetaNames.TYPE: 'scikit-learn_0.23',\n            client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: sofware_spec_uid\n}\n\n\n# Publish model in Watson Machine Learning repository on Cloud.\npublished_model = client.repository.store_model(\n    model=clf10,\n    meta_props=metadata,\n    training_data=X_train,\n    training_target=y_train)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# see the details of your published model:\nimport json\n\npublished_model_uid = client.repository.get_model_uid(published_model)\nmodel_details = client.repository.get_details(published_model_uid)\nprint(json.dumps(model_details, indent=2))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"feature_scaling\"></a>\n## 11. Deploy the Model\n\n[Top](#top)"}, {"metadata": {}, "cell_type": "code", "source": "metadata = {\n    client.deployments.ConfigurationMetaNames.NAME: \"PoC_NPS_Conference\",\n    client.deployments.ConfigurationMetaNames.ONLINE: {}\n}\n\ncreated_deployment = client.deployments.create(published_model_uid, meta_props=metadata)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# you need the deployment_uid to make predictions using the API\ndeployment_uid = client.deployments.get_uid(created_deployment)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# get model details\nclient.deployments.get_details(deployment_uid)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"feature_scaling\"></a>\n## 12. Make Predictions\n\n[Top](#top)"}, {"metadata": {}, "cell_type": "code", "source": "# you can get a scoring enpoint if you want to make predictions against the endpoint directly\nscoring_endpoint = client.deployments.get_scoring_href(created_deployment)\nprint(scoring_endpoint)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# the scoring payload needs to be of the following format. We are using a random sample from the test dataset in this payload\nscoring_values = list(X_test.sample().values[0])\nscoring_fields = X_test.columns\nscoring_payload = {client.deployments.ScoringMetaNames.INPUT_DATA: [{'fields': list(scoring_fields),\n                     'values': [scoring_values]}]}\n\n\n# scoring_payload = {\"input_data\": [{\"values\": [score_0, score_1]}]}", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "# let's see what the scoring payload looks like:\n# scoring_payload", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# finally, let's make some predictions. We use the deployment_uid and not the scoring URL since we using the API.\nresult = client.deployments.score(deployment_uid, scoring_payload)\nresult", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "predicted_class = result['predictions'][0]['values'][0][0]\nprint(f'predicted_class: {predicted_class}')\nprint(f'confidence score: {result[\"predictions\"][0][\"values\"][0][1][predicted_class]}')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# method to batch predict \ndef predict(row):\n    \n  scoring_values = list(X_test.sample().values[0])\n  scoring_fields = X_test.columns\n  scoring_payload = {client.deployments.ScoringMetaNames.INPUT_DATA: [{'fields': list(scoring_fields),\n                     'values': [list(row)]}]}\n\n  predict_flg = False #if prediction output fails for any reason\n  num_retries = 5 #make another 5 attempts\n  while(not predict_flg):\n      try:\n          predictions = client.deployments.score(deployment_uid, scoring_payload)\n          predict_flg = True\n      except Exception as ex:\n          if ('Status code: 504' in str(ex) or 'Status code: 503' in str(ex)) and num_retries > 1:\n              predict_flg = False\n              num_retries = num_retries - 1\n          else:\n              raise ex\n    \n  return [predictions['predictions'][0]['values'][0][0],predictions['predictions'][0]['values'][0][1][0]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def predict_batch(df):\n    df_temp = df.copy()\n    df_temp[['target', 'probability']] = df_temp.apply(lambda row: pd.Series(predict(row)), axis=1)\n    return df_temp", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#run predictions on first few records\nresult = predict_batch(X_train[0:15])\n\n#run predictions on all records\n#result = predict_batch(X_select)\nresult", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Congratulations! You have reached the end of the notebook\n\nHere are some more notebooks to try - https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-samples-overview.html?context=wdp&audience=wdp"}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}